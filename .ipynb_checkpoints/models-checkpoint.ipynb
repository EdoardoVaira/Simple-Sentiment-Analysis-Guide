{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb69b0e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis models\n",
    "\n",
    "In this notebook we will present all the models used for our problem and we will compare their performance.\n",
    "\n",
    "First of all, we load our preprocessed dataset and do all the different vectorizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22f7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#¬†Text processing\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from gensim import models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6c4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75c4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9010cf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31451\n",
      "(113292, 31451)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the model and transform the data\n",
    "bow = vectorizer.fit_transform(df['Content_cleaned'])\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc27ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31451\n",
      "(113292, 31451)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the model and transform the data\n",
    "tfidf = vectorizer.fit_transform(df['Content_cleaned'])\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4aec5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = models.KeyedVectors.load_word2vec_format(\n",
    "'../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dff6267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content_cleaned</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_pretrained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plsssss stoppppp giving screen limit like when...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>plss stopp give screen limit like ur watch thi...</td>\n",
       "      <td>[plss, stopp, give, screen, limit, like, ur, w...</td>\n",
       "      <td>[0.08365452, 0.0579847, 0.11433671, -0.0025425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>thumb up thumb up</td>\n",
       "      <td>[thumb, up, thumb, up]</td>\n",
       "      <td>[0.08703613, 0.07147217, -0.00390625, 0.005859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App is useful to certain phone brand ,,,,it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>app useful certain phone brand except phone tr...</td>\n",
       "      <td>[app, useful, certain, phone, brand, except, p...</td>\n",
       "      <td>[0.0644662, -0.0806833, -0.0020926339, 0.02535...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Score Sentiment  \\\n",
       "0  Plsssss stoppppp giving screen limit like when...      2  negative   \n",
       "1                                               Good      5  positive   \n",
       "2                                                 üëçüëç      5  positive   \n",
       "3                                               Good      3   neutral   \n",
       "4  App is useful to certain phone brand ,,,,it is...      1  negative   \n",
       "\n",
       "                                     Content_cleaned  \\\n",
       "0  plss stopp give screen limit like ur watch thi...   \n",
       "1                                               good   \n",
       "2                                  thumb up thumb up   \n",
       "3                                               good   \n",
       "4  app useful certain phone brand except phone tr...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [plss, stopp, give, screen, limit, like, ur, w...   \n",
       "1                                             [good]   \n",
       "2                             [thumb, up, thumb, up]   \n",
       "3                                             [good]   \n",
       "4  [app, useful, certain, phone, brand, except, p...   \n",
       "\n",
       "                                 word2vec_pretrained  \n",
       "0  [0.08365452, 0.0579847, 0.11433671, -0.0025425...  \n",
       "1  [0.040527344, 0.0625, -0.017456055, 0.07861328...  \n",
       "2  [0.08703613, 0.07147217, -0.00390625, 0.005859...  \n",
       "3  [0.040527344, 0.0625, -0.017456055, 0.07861328...  \n",
       "4  [0.0644662, -0.0806833, -0.0020926339, 0.02535...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_average_word2vec(tokens_list, model, vector_size):\n",
    "    \"\"\"\n",
    "    This function computes the average Word2Vec for a given list of tokens.\n",
    "    \"\"\"\n",
    "    # Filter the tokens that are present in the Word2Vec model\n",
    "    valid_tokens = [token for token in tokens_list if token in model]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(vector_size)\n",
    "    \n",
    "    # Compute the average Word2Vec\n",
    "    word_vectors = [model[token] for token in valid_tokens]\n",
    "    average_vector = np.mean(word_vectors, axis=0)\n",
    "    return average_vector\n",
    "\n",
    "# Tokenize the text data\n",
    "df['tokens'] = df['Content_cleaned'].apply(lambda x: x.split())\n",
    "\n",
    "# Compute the average Word2Vec for each row\n",
    "vector_size = w2v.vector_size\n",
    "df['word2vec_pretrained'] = df['tokens'].apply(lambda x: get_average_word2vec(x, w2v, vector_size))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862d91e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content_cleaned</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_pretrained</th>\n",
       "      <th>word2vec_cbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plsssss stoppppp giving screen limit like when...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>plss stopp give screen limit like ur watch thi...</td>\n",
       "      <td>[plss, stopp, give, screen, limit, like, ur, w...</td>\n",
       "      <td>[0.08365452, 0.0579847, 0.11433671, -0.0025425...</td>\n",
       "      <td>[-0.010158361, -0.2950956, 0.02295302, 0.05775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>[0.33362323, -1.5361803, -0.45669645, -0.59262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>thumb up thumb up</td>\n",
       "      <td>[thumb, up, thumb, up]</td>\n",
       "      <td>[0.08703613, 0.07147217, -0.00390625, 0.005859...</td>\n",
       "      <td>[-0.49321496, 0.1811941, -0.27961582, 1.002281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>[0.33362323, -1.5361803, -0.45669645, -0.59262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App is useful to certain phone brand ,,,,it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>app useful certain phone brand except phone tr...</td>\n",
       "      <td>[app, useful, certain, phone, brand, except, p...</td>\n",
       "      <td>[0.0644662, -0.0806833, -0.0020926339, 0.02535...</td>\n",
       "      <td>[-0.13318165, -0.09479263, -0.0055906163, 0.20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Score Sentiment  \\\n",
       "0  Plsssss stoppppp giving screen limit like when...      2  negative   \n",
       "1                                               Good      5  positive   \n",
       "2                                                 üëçüëç      5  positive   \n",
       "3                                               Good      3   neutral   \n",
       "4  App is useful to certain phone brand ,,,,it is...      1  negative   \n",
       "\n",
       "                                     Content_cleaned  \\\n",
       "0  plss stopp give screen limit like ur watch thi...   \n",
       "1                                               good   \n",
       "2                                  thumb up thumb up   \n",
       "3                                               good   \n",
       "4  app useful certain phone brand except phone tr...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [plss, stopp, give, screen, limit, like, ur, w...   \n",
       "1                                             [good]   \n",
       "2                             [thumb, up, thumb, up]   \n",
       "3                                             [good]   \n",
       "4  [app, useful, certain, phone, brand, except, p...   \n",
       "\n",
       "                                 word2vec_pretrained  \\\n",
       "0  [0.08365452, 0.0579847, 0.11433671, -0.0025425...   \n",
       "1  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "2  [0.08703613, 0.07147217, -0.00390625, 0.005859...   \n",
       "3  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "4  [0.0644662, -0.0806833, -0.0020926339, 0.02535...   \n",
       "\n",
       "                                       word2vec_cbow  \n",
       "0  [-0.010158361, -0.2950956, 0.02295302, 0.05775...  \n",
       "1  [0.33362323, -1.5361803, -0.45669645, -0.59262...  \n",
       "2  [-0.49321496, 0.1811941, -0.27961582, 1.002281...  \n",
       "3  [0.33362323, -1.5361803, -0.45669645, -0.59262...  \n",
       "4  [-0.13318165, -0.09479263, -0.0055906163, 0.20...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_average_word2vec2(tokens_list, model, vector_size):\n",
    "    valid_tokens = [token for token in tokens_list if token in model.wv]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(vector_size)\n",
    "    word_vectors = [model.wv[token] for token in valid_tokens]\n",
    "    average_vector = np.mean(word_vectors, axis=0)\n",
    "    return average_vector\n",
    "\n",
    "# Define model parameters\n",
    "vector_size = 300   # Dimensionality of the word vectors\n",
    "window_size = 5     # Context window size\n",
    "min_count = 1       # Minimum word frequency\n",
    "workers = multiprocessing.cpu_count()  # Number of worker threads to use\n",
    "\n",
    "# Train the Word2Vec model\n",
    "cbow = models.Word2Vec(df['tokens'].tolist(), vector_size=vector_size, sg=0, window=window_size, min_count=min_count, workers=workers)\n",
    "\n",
    "df['word2vec_cbow'] = df['tokens'].apply(lambda x: get_average_word2vec2(x, cbow, vector_size))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299c8acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors from GloVe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content_cleaned</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_pretrained</th>\n",
       "      <th>word2vec_cbow</th>\n",
       "      <th>glove_6B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plsssss stoppppp giving screen limit like when...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>plss stopp give screen limit like ur watch thi...</td>\n",
       "      <td>[plss, stopp, give, screen, limit, like, ur, w...</td>\n",
       "      <td>[0.08365452, 0.0579847, 0.11433671, -0.0025425...</td>\n",
       "      <td>[-0.010158361, -0.2950956, 0.02295302, 0.05775...</td>\n",
       "      <td>[-0.1198448, 0.12636456, 0.41294017, -0.217294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>[0.33362323, -1.5361803, -0.45669645, -0.59262...</td>\n",
       "      <td>[-0.030769, 0.11993, 0.53909, -0.43696, -0.739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>thumb up thumb up</td>\n",
       "      <td>[thumb, up, thumb, up]</td>\n",
       "      <td>[0.08703613, 0.07147217, -0.00390625, 0.005859...</td>\n",
       "      <td>[-0.49321496, 0.1811941, -0.27961582, 1.002281...</td>\n",
       "      <td>[-0.22568002, 0.342005, 0.248815, -0.577975, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>[0.33362323, -1.5361803, -0.45669645, -0.59262...</td>\n",
       "      <td>[-0.030769, 0.11993, 0.53909, -0.43696, -0.739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App is useful to certain phone brand ,,,,it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>app useful certain phone brand except phone tr...</td>\n",
       "      <td>[app, useful, certain, phone, brand, except, p...</td>\n",
       "      <td>[0.0644662, -0.0806833, -0.0020926339, 0.02535...</td>\n",
       "      <td>[-0.13318165, -0.09479263, -0.0055906163, 0.20...</td>\n",
       "      <td>[-0.21259494, -0.062381856, 0.21229614, 0.0178...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Score Sentiment  \\\n",
       "0  Plsssss stoppppp giving screen limit like when...      2  negative   \n",
       "1                                               Good      5  positive   \n",
       "2                                                 üëçüëç      5  positive   \n",
       "3                                               Good      3   neutral   \n",
       "4  App is useful to certain phone brand ,,,,it is...      1  negative   \n",
       "\n",
       "                                     Content_cleaned  \\\n",
       "0  plss stopp give screen limit like ur watch thi...   \n",
       "1                                               good   \n",
       "2                                  thumb up thumb up   \n",
       "3                                               good   \n",
       "4  app useful certain phone brand except phone tr...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [plss, stopp, give, screen, limit, like, ur, w...   \n",
       "1                                             [good]   \n",
       "2                             [thumb, up, thumb, up]   \n",
       "3                                             [good]   \n",
       "4  [app, useful, certain, phone, brand, except, p...   \n",
       "\n",
       "                                 word2vec_pretrained  \\\n",
       "0  [0.08365452, 0.0579847, 0.11433671, -0.0025425...   \n",
       "1  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "2  [0.08703613, 0.07147217, -0.00390625, 0.005859...   \n",
       "3  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "4  [0.0644662, -0.0806833, -0.0020926339, 0.02535...   \n",
       "\n",
       "                                       word2vec_cbow  \\\n",
       "0  [-0.010158361, -0.2950956, 0.02295302, 0.05775...   \n",
       "1  [0.33362323, -1.5361803, -0.45669645, -0.59262...   \n",
       "2  [-0.49321496, 0.1811941, -0.27961582, 1.002281...   \n",
       "3  [0.33362323, -1.5361803, -0.45669645, -0.59262...   \n",
       "4  [-0.13318165, -0.09479263, -0.0055906163, 0.20...   \n",
       "\n",
       "                                            glove_6B  \n",
       "0  [-0.1198448, 0.12636456, 0.41294017, -0.217294...  \n",
       "1  [-0.030769, 0.11993, 0.53909, -0.43696, -0.739...  \n",
       "2  [-0.22568002, 0.342005, 0.248815, -0.577975, -...  \n",
       "3  [-0.030769, 0.11993, 0.53909, -0.43696, -0.739...  \n",
       "4  [-0.21259494, -0.062381856, 0.21229614, 0.0178...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the GloVe embeddings file\n",
    "glove_file = '../glove.6B.100d.txt'\n",
    "\n",
    "# Load the GloVe embeddings into a dictionary\n",
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load the GloVe embeddings\n",
    "glove_6b = load_glove_embeddings(glove_file)\n",
    "print(f\"Loaded {len(glove_6b)} word vectors from GloVe.\")\n",
    "\n",
    "# Define a function to get the average GloVe vector for a list of tokens\n",
    "def get_average_glove(tokens_list, embeddings, embedding_dim):\n",
    "    valid_tokens = [token for token in tokens_list if token in embeddings]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(embedding_dim)\n",
    "    word_vectors = [embeddings[token] for token in valid_tokens]\n",
    "    average_vector = np.mean(word_vectors, axis=0)\n",
    "    return average_vector\n",
    "\n",
    "# Define the embedding dimension (e.g., 100 for 'glove.6B.100d.txt')\n",
    "embedding_dim = 100\n",
    "\n",
    "# Compute the average GloVe vector for each row\n",
    "df['glove_6B'] = df['tokens'].apply(lambda x: get_average_glove(x, glove_6b, embedding_dim))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dcc6bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors from GloVe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content_cleaned</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_pretrained</th>\n",
       "      <th>word2vec_cbow</th>\n",
       "      <th>glove_6B</th>\n",
       "      <th>glove_twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plsssss stoppppp giving screen limit like when...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>plss stopp give screen limit like ur watch thi...</td>\n",
       "      <td>[plss, stopp, give, screen, limit, like, ur, w...</td>\n",
       "      <td>[0.08365452, 0.0579847, 0.11433671, -0.0025425...</td>\n",
       "      <td>[-0.010158361, -0.2950956, 0.02295302, 0.05775...</td>\n",
       "      <td>[-0.1198448, 0.12636456, 0.41294017, -0.217294...</td>\n",
       "      <td>[0.123258926, 0.09078163, -0.101420276, 0.2712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>[0.33362323, -1.5361803, -0.45669645, -0.59262...</td>\n",
       "      <td>[-0.030769, 0.11993, 0.53909, -0.43696, -0.739...</td>\n",
       "      <td>[0.091552, 0.093336, -0.028113, 0.3699, 0.1895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>thumb up thumb up</td>\n",
       "      <td>[thumb, up, thumb, up]</td>\n",
       "      <td>[0.08703613, 0.07147217, -0.00390625, 0.005859...</td>\n",
       "      <td>[-0.49321496, 0.1811941, -0.27961582, 1.002281...</td>\n",
       "      <td>[-0.22568002, 0.342005, 0.248815, -0.577975, -...</td>\n",
       "      <td>[0.26894343, -0.28983998, 0.164455, -0.166473,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[0.040527344, 0.0625, -0.017456055, 0.07861328...</td>\n",
       "      <td>[0.33362323, -1.5361803, -0.45669645, -0.59262...</td>\n",
       "      <td>[-0.030769, 0.11993, 0.53909, -0.43696, -0.739...</td>\n",
       "      <td>[0.091552, 0.093336, -0.028113, 0.3699, 0.1895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>App is useful to certain phone brand ,,,,it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>app useful certain phone brand except phone tr...</td>\n",
       "      <td>[app, useful, certain, phone, brand, except, p...</td>\n",
       "      <td>[0.0644662, -0.0806833, -0.0020926339, 0.02535...</td>\n",
       "      <td>[-0.13318165, -0.09479263, -0.0055906163, 0.20...</td>\n",
       "      <td>[-0.21259494, -0.062381856, 0.21229614, 0.0178...</td>\n",
       "      <td>[0.30852813, 0.06642222, -0.07303124, 0.210921...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Score Sentiment  \\\n",
       "0  Plsssss stoppppp giving screen limit like when...      2  negative   \n",
       "1                                               Good      5  positive   \n",
       "2                                                 üëçüëç      5  positive   \n",
       "3                                               Good      3   neutral   \n",
       "4  App is useful to certain phone brand ,,,,it is...      1  negative   \n",
       "\n",
       "                                     Content_cleaned  \\\n",
       "0  plss stopp give screen limit like ur watch thi...   \n",
       "1                                               good   \n",
       "2                                  thumb up thumb up   \n",
       "3                                               good   \n",
       "4  app useful certain phone brand except phone tr...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [plss, stopp, give, screen, limit, like, ur, w...   \n",
       "1                                             [good]   \n",
       "2                             [thumb, up, thumb, up]   \n",
       "3                                             [good]   \n",
       "4  [app, useful, certain, phone, brand, except, p...   \n",
       "\n",
       "                                 word2vec_pretrained  \\\n",
       "0  [0.08365452, 0.0579847, 0.11433671, -0.0025425...   \n",
       "1  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "2  [0.08703613, 0.07147217, -0.00390625, 0.005859...   \n",
       "3  [0.040527344, 0.0625, -0.017456055, 0.07861328...   \n",
       "4  [0.0644662, -0.0806833, -0.0020926339, 0.02535...   \n",
       "\n",
       "                                       word2vec_cbow  \\\n",
       "0  [-0.010158361, -0.2950956, 0.02295302, 0.05775...   \n",
       "1  [0.33362323, -1.5361803, -0.45669645, -0.59262...   \n",
       "2  [-0.49321496, 0.1811941, -0.27961582, 1.002281...   \n",
       "3  [0.33362323, -1.5361803, -0.45669645, -0.59262...   \n",
       "4  [-0.13318165, -0.09479263, -0.0055906163, 0.20...   \n",
       "\n",
       "                                            glove_6B  \\\n",
       "0  [-0.1198448, 0.12636456, 0.41294017, -0.217294...   \n",
       "1  [-0.030769, 0.11993, 0.53909, -0.43696, -0.739...   \n",
       "2  [-0.22568002, 0.342005, 0.248815, -0.577975, -...   \n",
       "3  [-0.030769, 0.11993, 0.53909, -0.43696, -0.739...   \n",
       "4  [-0.21259494, -0.062381856, 0.21229614, 0.0178...   \n",
       "\n",
       "                                       glove_twitter  \n",
       "0  [0.123258926, 0.09078163, -0.101420276, 0.2712...  \n",
       "1  [0.091552, 0.093336, -0.028113, 0.3699, 0.1895...  \n",
       "2  [0.26894343, -0.28983998, 0.164455, -0.166473,...  \n",
       "3  [0.091552, 0.093336, -0.028113, 0.3699, 0.1895...  \n",
       "4  [0.30852813, 0.06642222, -0.07303124, 0.210921...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the GloVe embeddings file\n",
    "glove_file = '../glove.twitter.27B.100d.txt'\n",
    "\n",
    "# Load the GloVe embeddings into a dictionary\n",
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load the GloVe embeddings\n",
    "glove_twitter = load_glove_embeddings(glove_file)\n",
    "print(f\"Loaded {len(glove_twitter)} word vectors from GloVe.\")\n",
    "\n",
    "# Define a function to get the average GloVe vector for a list of tokens\n",
    "def get_average_glove(tokens_list, embeddings, embedding_dim):\n",
    "    valid_tokens = [token for token in tokens_list if token in embeddings]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(embedding_dim)\n",
    "    word_vectors = [embeddings[token] for token in valid_tokens]\n",
    "    average_vector = np.mean(word_vectors, axis=0)\n",
    "    return average_vector\n",
    "\n",
    "# Define the embedding dimension (e.g., 100 for 'glove.6B.100d.txt')\n",
    "embedding_dim = 100\n",
    "\n",
    "# Compute the average GloVe vector for each row\n",
    "df['glove_twitter'] = df['tokens'].apply(lambda x: get_average_glove(x, glove_twitter, embedding_dim))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae405d1",
   "metadata": {},
   "source": [
    "\n",
    "### Preparing the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54527bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df['Sentiment']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c2588",
   "metadata": {},
   "source": [
    "### Performing the train-test splits for the different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0349ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train, bow_test, y_train, y_test = train_test_split(bow, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de93546",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train, tfidf_test, y_train, y_test = train_test_split(tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d2c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_pre = np.vstack(df['word2vec_pretrained'].values)\n",
    "\n",
    "w2v_pre_train, w2v_pre_test, y_train, y_test = train_test_split(w2v_pre, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "084a1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cbow = np.vstack(df['word2vec_cbow'].values)\n",
    "\n",
    "w2v_cbow_train, w2v_cbow_test, y_train, y_test = train_test_split(w2v_cbow, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe2e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_6b = np.vstack(df['glove_6B'].values)\n",
    "\n",
    "glove_6b_train, glove_6b_test, y_train, y_test = train_test_split(glove_6b, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8d493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_twitter = np.vstack(df['glove_twitter'].values)\n",
    "\n",
    "glove_twitter_train, glove_twitter_test, y_train, y_test = train_test_split(glove_twitter, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05caca3e",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7046d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using BoW and Logistic Regression: 0.735248687055916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because BoW has sparse matrix format\n",
    "bow_train_scaled = scaler.fit_transform(bow_train)\n",
    "bow_test_scaled = scaler.transform(bow_test)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_bow = LogisticRegression()\n",
    "lr_bow.fit(bow_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_bow.predict(bow_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using BoW and Logistic Regression: {accuracy}\")\n",
    "\n",
    "results = {}\n",
    "results['lr_bow'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ae0345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using TFIDF and Logistic Regression: 0.733659914382806\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because BoW has sparse matrix format\n",
    "tfidf_train_scaled = scaler.fit_transform(tfidf_train)\n",
    "tfidf_test_scaled = scaler.transform(tfidf_test)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_tfidf = LogisticRegression()\n",
    "lr_tfidf.fit(tfidf_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_tfidf.predict(tfidf_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using TFIDF and Logistic Regression: {accuracy}\")\n",
    "\n",
    "results['lr_tfidf'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9206738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using W2V_pretrained and Logistic Regression: 0.7758065227944746\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "lr_w2v_pre = LogisticRegression()\n",
    "lr_w2v_pre.fit(w2v_pre_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_w2v_pre.predict(w2v_pre_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using W2V_pretrained and Logistic Regression: {accuracy}\")\n",
    "\n",
    "results['lr_w2v_pre'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa978ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using W2V_CBOW and Logistic Regression: 0.7860452800211837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because BoW has sparse matrix format\n",
    "w2v_cbow_train_scaled = scaler.fit_transform(w2v_cbow_train)\n",
    "w2v_cbow_test_scaled = scaler.transform(w2v_cbow_test)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_w2v_cbow = LogisticRegression(max_iter=500)\n",
    "lr_w2v_cbow.fit(w2v_cbow_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_w2v_cbow.predict(w2v_cbow_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using W2V_CBOW and Logistic Regression: {accuracy}\")\n",
    "\n",
    "results['lr_w2b_cbow'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2ec735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using W2V_CBOW and Logistic Regression: 0.7518425349750651\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because BoW has sparse matrix format\n",
    "glove_6b_train_scaled = scaler.fit_transform(glove_6b_train)\n",
    "glove_6b_test_scaled = scaler.transform(glove_6b_test)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_glove_6b = LogisticRegression(max_iter=500)\n",
    "lr_glove_6b.fit(glove_6b_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_glove_6b.predict(glove_6b_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using W2V_CBOW and Logistic Regression: {accuracy}\")\n",
    "\n",
    "results['lr_glove_6b'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3fd0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using W2V_CBOW and Logistic Regression: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=False)  # with_mean=False because BoW has sparse matrix format\n",
    "glove_twitter_train_scaled = scaler.fit_transform(glove_twitter_train)\n",
    "glove_twitter_test_scaled = scaler.transform(glove_twitter_test)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_glove_twitter = LogisticRegression(max_iter=500)\n",
    "lr_glove_twitter.fit(glove_twitter_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_glove_twitter.predict(glove_twitter_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using W2V_CBOW and Logistic Regression: {accuracy}\")\n",
    "\n",
    "results['lr_glove_twitter'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a2d613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model  Accuracy\n",
      "0            lr_bow  0.735249\n",
      "1          lr_tfidf  0.733660\n",
      "2        lr_w2v_pre  0.775807\n",
      "3       lr_w2b_cbow  0.786045\n",
      "4       lr_glove_6b  0.751843\n",
      "5  lr_glove_twitter  0.761905\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "\n",
    "# Print the results table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa727497",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99e37c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using BoW and SVC: 0.7736881592303279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_bow = LinearSVC(C=1, max_iter=5000)\n",
    "svc_bow.fit(bow_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svc_bow.predict(bow_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using BoW and SVC: {accuracy}\")\n",
    "\n",
    "results = {}\n",
    "results['svc_bow'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1358f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using tfidf and SVC: 0.7867955337834855\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf = LinearSVC(C=1, max_iter=5000)\n",
    "svc_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svc_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using tfidf and SVC: {accuracy}\")\n",
    "\n",
    "results['svc_tfidf'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6319ebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using w2v_pre and SVC: 0.7766891742795358\n"
     ]
    }
   ],
   "source": [
    "svc_w2v_pre = LinearSVC(C=1, max_iter=5000)\n",
    "svc_w2v_pre.fit(w2v_pre_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svc_w2v_pre.predict(w2v_pre_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using w2v_pre and SVC: {accuracy}\")\n",
    "\n",
    "results['svc_w2v_pre'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c28fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using w2v_cbow and SVC: 0.7862218103181958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc_w2v_cbow = LinearSVC(C=1, max_iter=5000)\n",
    "svc_w2v_cbow.fit(w2v_cbow_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svc_w2v_cbow.predict(w2v_cbow_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using w2v_cbow and SVC: {accuracy}\")\n",
    "\n",
    "results['svc_w2v_cbow'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb2e8358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using glove_6b and SVC: 0.7530341144798977\n"
     ]
    }
   ],
   "source": [
    "svc_glove_6b = LinearSVC(C=1, max_iter=5000)\n",
    "svc_glove_6b.fit(glove_6b_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svc_glove_6b.predict(glove_6b_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using glove_6b and SVC: {accuracy}\")\n",
    "\n",
    "results['svc_glove_6b'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d426e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoch\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using glove_twitter and SVC: 0.7615958338849905\n"
     ]
    }
   ],
   "source": [
    "svc_glove_twitter = LinearSVC(C=1, max_iter=5000)\n",
    "svc_glove_twitter.fit(glove_twitter_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svc_glove_twitter.predict(glove_twitter_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using glove_twitter and SVC: {accuracy}\")\n",
    "\n",
    "results['svc_glove_twitter'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bfabc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Accuracy\n",
      "0            svc_bow  0.773688\n",
      "1          svc_tfidf  0.786796\n",
      "2        svc_w2v_pre  0.776689\n",
      "3       svc_w2v_cbow  0.786222\n",
      "4       svc_glove_6b  0.753034\n",
      "5  svc_glove_twitter  0.761596\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "\n",
    "# Print the results table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d185702",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de32fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using BoW and RF: 0.7834414581402533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_bow = RandomForestClassifier()\n",
    "\n",
    "rf_bow.fit(bow_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_bow.predict(bow_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using BoW and RF: {accuracy}\")\n",
    "\n",
    "results = {}\n",
    "results['rf_bow'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7a674b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using TFIDF and RF: 0.7811465642790943\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "rf_tfidf = RandomForestClassifier()\n",
    "rf_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using TFIDF and RF: {accuracy}\")\n",
    "\n",
    "results['rf_tfidf'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f39b7f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using W2V_pretrained and RF: 0.7578445650734807\n"
     ]
    }
   ],
   "source": [
    "rf_w2v_pre = RandomForestClassifier()\n",
    "rf_w2v_pre.fit(w2v_pre_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_w2v_pre.predict(w2v_pre_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using W2V_pretrained and RF: {accuracy}\")\n",
    "\n",
    "results['rf_w2v_pre'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be2b8973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using W2V_cbow and RF: 0.7751445341806787\n"
     ]
    }
   ],
   "source": [
    "rf_w2v_cbow = RandomForestClassifier()\n",
    "rf_w2v_cbow.fit(w2v_cbow_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_w2v_cbow.predict(w2v_cbow_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using W2V_cbow and RF: {accuracy}\")\n",
    "\n",
    "results['rf_w2v_cbow'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcc216ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using glove_6b and RF: 0.7417803080453683\n"
     ]
    }
   ],
   "source": [
    "rf_glove_6b = RandomForestClassifier()\n",
    "rf_glove_6b.fit(glove_6b_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_glove_6b.predict(glove_6b_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using glove_6b and RF: {accuracy}\")\n",
    "\n",
    "results['rf_glove_6b'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1474c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using glove_twitter and RF: 0.7510481486385101\n"
     ]
    }
   ],
   "source": [
    "rf_glove_twitter = RandomForestClassifier()\n",
    "rf_glove_twitter.fit(glove_twitter_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_glove_twitter.predict(glove_twitter_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy using glove_twitter and RF: {accuracy}\")\n",
    "\n",
    "results['rf_glove_twitter'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5d9f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model  Accuracy\n",
      "0            rf_bow  0.783441\n",
      "1          rf_tfidf  0.781147\n",
      "2        rf_w2v_pre  0.757845\n",
      "3       rf_w2v_cbow  0.775145\n",
      "4       rf_glove_6b  0.741780\n",
      "5  rf_glove_twitter  0.751048\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "\n",
    "# Print the results table\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

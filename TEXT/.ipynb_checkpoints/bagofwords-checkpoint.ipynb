{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Text Analysis Using Bag of Words (BoW)\n",
    "\n",
    "Welcome to this educational notebook where we explore the Bag of Words (BoW) model, a foundational technique in natural language processing (NLP). BoW is particularly useful for converting text into numerical representations that can be fed into various machine learning models. This notebook will guide you through applying the BoW model to analyze customer reviews of the Netflix app.\n",
    "\n",
    "### What is Bag of Words?\n",
    "\n",
    "The Bag of Words model is a way of extracting features from text for use in modeling, such as machine learning algorithms. It involves two primary steps:\n",
    "1. **Tokenization**: Splitting text into individual words or tokens.\n",
    "2. **Vectorization**: Counting how many times each token occurs in each document and using this count as a feature.\n",
    "\n",
    "### Why is BoW Important?\n",
    "\n",
    "BoW is crucial for many NLP tasks because it simplifies the complex task of understanding human language by reducing text to a bag of individual words. This model can be used for document classification, sentiment analysis, and other applications where text needs to be converted into a form that algorithms can process. Let's explore how we can implement and utilize this model effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset Preview\n",
    "\n",
    "Below is a preview of the dataset used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame with Netflix app reviews\n",
    "df = pd.DataFrame({\n",
    "    'Content_cleaned': [\n",
    "        'great new features but crashes often',\n",
    "        'love love the content but it crashes',\n",
    "        'crashes too much frustrating',\n",
    "        'great content easy to use great'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the DataFrame\n",
    "\n",
    "Our DataFrame `df` contains one column, `Content_cleaned`, which holds the text of customer reviews. These texts are preprocessed, meaning they are cleaned of extraneous symbols, and lowercased to standardize the input for our BoW model. Like we did in the `text_preprocessing.ipynb` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great new features but crashes often</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love love the content but it crashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crashes too much frustrating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great content easy to use great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Content_cleaned\n",
       "0  great new features but crashes often\n",
       "1  love love the content but it crashes\n",
       "2          crashes too much frustrating\n",
       "3       great content easy to use great"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Review</th>\n",
       "      <th>but</th>\n",
       "      <th>content</th>\n",
       "      <th>crashes</th>\n",
       "      <th>easy</th>\n",
       "      <th>features</th>\n",
       "      <th>frustrating</th>\n",
       "      <th>great</th>\n",
       "      <th>it</th>\n",
       "      <th>love</th>\n",
       "      <th>much</th>\n",
       "      <th>new</th>\n",
       "      <th>often</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great new features but crashes often</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love love the content but it crashes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crashes too much frustrating</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great content easy to use great</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Original_Review  but  content  crashes  easy  \\\n",
       "0  great new features but crashes often    1        0        1     0   \n",
       "1  love love the content but it crashes    1        1        1     0   \n",
       "2          crashes too much frustrating    0        0        1     0   \n",
       "3       great content easy to use great    0        1        0     1   \n",
       "\n",
       "   features  frustrating  great  it  love  much  new  often  the  to  too  use  \n",
       "0         1            0      1   0     0     0    1      1    0   0    0    0  \n",
       "1         0            0      0   1     2     0    0      0    1   0    0    0  \n",
       "2         0            1      0   0     0     1    0      0    0   0    1    0  \n",
       "3         0            0      2   0     0     0    0      0    0   1    0    1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer, our BoW tool\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the reviews into a matrix of token counts\n",
    "document_term_matrix = vectorizer.fit_transform(df['Content_cleaned'])\n",
    "\n",
    "# Extract the feature names (vocabulary) from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the matrix into a readable DataFrame with tokens as columns\n",
    "bow_df = pd.DataFrame(document_term_matrix.toarray(), columns=feature_names, index=df.index)\n",
    "\n",
    "# Insert the original reviews as the first column in the DataFrame\n",
    "bow_df.insert(0, 'Original_Review', df['Content_cleaned'])\n",
    "\n",
    "# Display the resulting Bag of Words matrix\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the Document-Term Matrix\n",
    "\n",
    "The document-term matrix we've created transforms our text data into a format that can be used by machine learning algorithms. Each row corresponds to a review, and each column corresponds to a unique word in our corpus of reviews. The values in the matrix represent the frequency of each word in each document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of the Bag of Words Model\n",
    "\n",
    "### Pros:\n",
    "- **Simplicity**: BoW is easy to implement and interpret.\n",
    "- **Flexibility**: Easily adaptable for various NLP tasks.\n",
    "- **Scalability**: Works well with large datasets and can be easily scaled.\n",
    "\n",
    "### Cons:\n",
    "- **Context Ignorance**: Fails to capture the context and semantics of words as order is not preserved.\n",
    "- **High Dimensionality**: Can lead to very high-dimensional feature spaces with sparse matrices, especially with large vocabularies.\n",
    "- **Common Words Issue**: Frequent words may dominate unless techniques like TF-IDF are used to normalize the counts.\n",
    "- **Out-Of-Vocabulary Issue**: It does not work with new sequences that contain words not included in the vocabulary used for fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Flaws of the Bag of Words Model\n",
    "\n",
    "### 1. Context Ignorance\n",
    "- **Issue**: BoW ignores the order of words, losing the context and grammatical relationships.\n",
    "- **Impact**: Different meanings that depend on word order are not captured, potentially misleading the analysis.\n",
    "\n",
    "### 2. High Dimensionality\n",
    "- **Issue**: BoW creates large, sparse feature spaces with every unique word as a feature.\n",
    "- **Impact**: This can lead to computational inefficiencies and challenges in handling the data effectively.\n",
    "\n",
    "### 3. Common Words Domination\n",
    "- **Issue**: Frequent common words can dominate unless techniques like TF-IDF are used.\n",
    "- **Impact**: These words often provide little useful information and can skew analysis results.\n",
    "\n",
    "### 4. Lack of Semantic Analysis\n",
    "- **Issue**: BoW does not understand the meanings behind words.\n",
    "- **Impact**: The model cannot differentiate words with multiple meanings, limiting its effectiveness in semantic tasks.\n",
    "\n",
    "### 5. Limited Vocabulary\n",
    "- **Issue**: BoW trains on a specific vocabulary.\n",
    "- **Impact**: The model cannot work with new sequences that contain unseen words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Text Analysis Using Bag of Words (BoW)\n",
    "\n",
    "Welcome to this educational notebook where we explore the Bag of Words (BoW) model, a foundational technique in natural language processing (NLP). BoW is particularly useful for converting text into numerical representations that can be fed into various machine learning models. This notebook will guide you through applying the BoW model to analyze customer reviews of the Netflix app.\n",
    "\n",
    "### What is Bag of Words?\n",
    "\n",
    "The Bag of Words model is a way of extracting features from text for use in modeling, such as machine learning algorithms. It involves two primary steps:\n",
    "1. **Tokenization**: Splitting text into individual words or tokens.\n",
    "2. **Vectorization**: Counting how many times each token in the dataset occurs in each document and using this count as a feature.\n",
    "\n",
    "### Why is BoW Important?\n",
    "\n",
    "BoW is crucial for many NLP tasks because it simplifies the complex task of understanding human language by reducing text to a bag of individual words. This model can be used for document classification, sentiment analysis, and other applications where text needs to be converted into a form that algorithms can process. Let's explore how we can implement and utilize this model effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset Preview\n",
    "\n",
    "Below is a small preview of the dataset we will use in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame with Netflix app reviews\n",
    "df = pd.DataFrame({\n",
    "    'Content_cleaned': [\n",
    "        'the app is great new features but crashes often',\n",
    "        'love the app love the content but it crashes',\n",
    "        'the app crashes too much it is frustrating',\n",
    "        'the content is great it is easy to use it is great'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the DataFrame\n",
    "\n",
    "Our DataFrame `df` contains one column, `Content_cleaned`, which holds the text of customer reviews. These texts are preprocessed, meaning they are cleaned of extraneous symbols, and lowercased to standardize the input for our BoW model. This process is done in the `text_preprocessing.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the app is great new features but crashes often</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love the app love the content but it crashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the app crashes too much it is frustrating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the content is great it is easy to use it is g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Content_cleaned\n",
       "0    the app is great new features but crashes often\n",
       "1       love the app love the content but it crashes\n",
       "2         the app crashes too much it is frustrating\n",
       "3  the content is great it is easy to use it is g..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Review</th>\n",
       "      <th>app</th>\n",
       "      <th>but</th>\n",
       "      <th>content</th>\n",
       "      <th>crashes</th>\n",
       "      <th>easy</th>\n",
       "      <th>features</th>\n",
       "      <th>frustrating</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>love</th>\n",
       "      <th>much</th>\n",
       "      <th>new</th>\n",
       "      <th>often</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the app is great new features but crashes often</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love the app love the content but it crashes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the app crashes too much it is frustrating</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the content is great it is easy to use it is g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Original_Review  app  but  content  \\\n",
       "0    the app is great new features but crashes often    1    1        0   \n",
       "1       love the app love the content but it crashes    1    1        1   \n",
       "2         the app crashes too much it is frustrating    1    0        0   \n",
       "3  the content is great it is easy to use it is g...    0    0        1   \n",
       "\n",
       "   crashes  easy  features  frustrating  great  is  it  love  much  new  \\\n",
       "0        1     0         1            0      1   1   0     0     0    1   \n",
       "1        1     0         0            0      0   0   1     2     0    0   \n",
       "2        1     0         0            1      0   1   1     0     1    0   \n",
       "3        0     1         0            0      2   3   2     0     0    0   \n",
       "\n",
       "   often  the  to  too  use  \n",
       "0      1    1   0    0    0  \n",
       "1      0    2   0    0    0  \n",
       "2      0    1   0    1    0  \n",
       "3      0    1   1    0    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer, our BoW tool\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the reviews into a matrix of token counts\n",
    "document_term_matrix = vectorizer.fit_transform(df['Content_cleaned'])\n",
    "\n",
    "# Extract the feature names (vocabulary) from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the matrix into a readable DataFrame with tokens as columns\n",
    "bow_df = pd.DataFrame(document_term_matrix.toarray(), columns=feature_names, index=df.index)\n",
    "\n",
    "# Insert the original reviews as the first column in the DataFrame\n",
    "bow_df.insert(0, 'Original_Review', df['Content_cleaned'])\n",
    "\n",
    "# Display the resulting Bag of Words matrix\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the Matrix\n",
    "\n",
    "The matrix we've created transforms our text data into a format that can be used by machine learning algorithms. Each row corresponds to a review, and each column corresponds to a unique word in our corpus of reviews. The values in the matrix represent the frequency of each word in each review.\n",
    "\n",
    "\n",
    "### Applying BoW on our entire dataset\n",
    "\n",
    "Next we will perform the BoW algorithm on our entire dataset. We notice that it has a vocabulary of 39783 words and each document will have this size. The columns are the vocabulary alphabetically sorted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39783\n",
      "(113292, 39783)\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('../DATASETS/preprocessed_text.csv')\n",
    "\n",
    "# Filling empty text that occured after the text preprocessing\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the model and transform the data\n",
    "bow = vectorizer.fit_transform(df['content_cleaned'])\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(bow.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we notice that the vectorized sequences are stored in a sparse matrix format. Basically, this means that it shows only the columns of the vector that are non zero, which is essential in such high dimensional feature spaces. Below we see two examples of the sparse matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thumbs_up thumbs_up\n",
      "  (0, 34610)\t2\n"
     ]
    }
   ],
   "source": [
    "print(df['content_cleaned'][2])\n",
    "print(bow[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "always promoting anti hindu shows\n",
      "  (0, 2589)\t1\n",
      "  (0, 27041)\t1\n",
      "  (0, 3013)\t1\n",
      "  (0, 16517)\t1\n",
      "  (0, 31090)\t1\n"
     ]
    }
   ],
   "source": [
    "print(df['content_cleaned'][5])\n",
    "print(bow[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of the Bag of Words Model\n",
    "\n",
    "### Pros:\n",
    "- **Simplicity**: BoW is easy and fast to implement and interpret.\n",
    "- **Flexibility**: Easily adaptable for various NLP tasks.\n",
    "- **Scalability**: Works well with large datasets and can be easily scaled.\n",
    "\n",
    "### Cons:\n",
    "- **Context Ignorance**: Fails to capture the context and semantics of words as order is not preserved.\n",
    "- **High Dimensionality**: Can lead to very high-dimensional feature spaces with sparse matrices, especially with large vocabularies.\n",
    "- **Common Words Issue**: Frequent words may dominate unless techniques like TF-IDF are used to normalize the counts.\n",
    "- **Out-Of-Vocabulary Issue**: It does not work with new sequences that contain words not included in the vocabulary used for fitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

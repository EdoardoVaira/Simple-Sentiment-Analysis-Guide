{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF builds on the Bag of Words (BoW) approach to help us better understand and analyze text. Both TF-IDF and BoW represent text data as numerical values. But they differ in how they handle word importance.\n",
    "\n",
    "The Bag of Words (BoW) method counts how often each word appears in a document, treating all words the same. This can be a problem, because common words like \"and\" or \"the\" might dominate the results. Even if they don't have much meaning.\n",
    "\n",
    "TF-IDF gets around this by not only counting word frequency (like BoW). But also considering how common or rare a word is across all documents. This makes common words less important and increases the importance of rare words. This makes TF-IDF a more sophisticated method. It helps to highlight the words that are important for understanding the content of a document.\n",
    "\n",
    "In short, BoW gives you a basic word count. But TF-IDF goes a step further by weighting these counts based on word importance. Thus, TF-IDF provides a more accurate reflection of the document's key messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Calculating TF-IDF\n",
    "\n",
    "#### Step 1: Start with 3 Phrases\n",
    "Let's use the following phrases as our documents (that eventually will be our reviews):\n",
    "\n",
    "1. \"The car is fast\"\n",
    "2. \"The car is red\"\n",
    "3. \"The fast car is blue\"\n",
    "\n",
    "#### Step 2: Create the Term Frequency (TF) Matrix\n",
    "First, list all unique words across the phrases: `the`, `car`, `is`, `fast`, `red`, `blue`.\n",
    "\n",
    "**TF Formula:**  \n",
    "TF = (Number of times the word appears in a phrase) / (Total number of words in the phrase)\n",
    "\n",
    "| Term   | Phrase 1 (\"The car is fast\") | Phrase 2 (\"The car is red\") | Phrase 3 (\"The fast car is blue\") |\n",
    "|--------|------------------------------|-----------------------------|-----------------------------------|\n",
    "| the    | 1/4 = 0.25                   | 1/4 = 0.25                  | 1/5 = 0.20                        |\n",
    "| car    | 1/4 = 0.25                   | 1/4 = 0.25                  | 1/5 = 0.20                        |\n",
    "| is     | 1/4 = 0.25                   | 1/4 = 0.25                  | 1/5 = 0.20                        |\n",
    "| fast   | 1/4 = 0.25                   | 0/4 = 0                     | 1/5 = 0.20                        |\n",
    "| red    | 0/4 = 0                      | 1/4 = 0.25                  | 0/5 = 0                           |\n",
    "| blue   | 0/4 = 0                      | 0/4 = 0                     | 1/5 = 0.20                        |\n",
    "\n",
    "#### Step 3: Create the Inverse Document Frequency (IDF) Matrix\n",
    "**IDF Formula:**  \n",
    "IDF = log(Total number of phrases / Number of phrases containing the word)\n",
    "\n",
    "For 3 phrases:\n",
    "\n",
    "| Term   | Document Frequency (DF) | IDF Calculation                      | IDF  |\n",
    "|--------|-------------------------|--------------------------------------|------|\n",
    "| the    | 3                        | log(3 / 3) = log(1)                  | 0    |\n",
    "| car    | 3                        | log(3 / 3) = log(1)                  | 0    |\n",
    "| is     | 3                        | log(3 / 3) = log(1)                  | 0    |\n",
    "| fast   | 2                        | log(3 / 2)                          | 0.18 |\n",
    "| red    | 1                        | log(3 / 1)                          | 0.48 |\n",
    "| blue   | 1                        | log(3 / 1)                          | 0.48 |\n",
    "\n",
    "#### Step 4: Calculate the TF-IDF Matrix\n",
    "**TF-IDF Formula:**  \n",
    "TF-IDF = TF * IDF\n",
    "\n",
    "| Term   | TF-IDF for Phrase 1        | TF-IDF for Phrase 2       | TF-IDF for Phrase 3       |\n",
    "|--------|----------------------------|---------------------------|---------------------------|\n",
    "| the    | 0.25 * 0 = 0               | 0.25 * 0 = 0              | 0.20 * 0 = 0              |\n",
    "| car    | 0.25 * 0 = 0               | 0.25 * 0 = 0              | 0.20 * 0 = 0              |\n",
    "| is     | 0.25 * 0 = 0               | 0.25 * 0 = 0              | 0.20 * 0 = 0              |\n",
    "| fast   | 0.25 * 0.18 = 0.045        | 0 * 0.18 = 0              | 0.20 * 0.18 = 0.036       |\n",
    "| red    | 0 * 0.48 = 0               | 0.25 * 0.48 = 0.12        | 0 * 0.48 = 0              |\n",
    "| blue   | 0 * 0.48 = 0               | 0 * 0.48 = 0              | 0.20 * 0.48 = 0.096       |\n",
    "\n",
    "#### Final TF-IDF Scores\n",
    "- **Phrase 1** (\"The car is fast\"): Important word - `fast` (0.045)\n",
    "- **Phrase 2** (\"The car is red\"): Important word - `red` (0.12)\n",
    "- **Phrase 3** (\"The fast car is blue\"): Important words - `fast` (0.036), `blue` (0.096)\n",
    "\n",
    "### Summary\n",
    "\n",
    "It's amazing to see how TF-IDF highlights the most important words. All the sentences contain `the car is`, and these words got a TF-IDF score of 0. But, the parts not \"in common\" got higher scores, such as: `fast`, `red` and `blue`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation in Python\n",
    "\n",
    "Let's begin by importing the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by creating a sample dataset. Just like we did in BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame with Netflix app reviews\n",
    "df = pd.DataFrame({\n",
    "    'Content_cleaned': [\n",
    "        'the app is great new features but crashes often',\n",
    "        'love the app love the content but it crashes',\n",
    "        'the app crashes too much it is frustrating',\n",
    "        'the content is great it is easy to use it is great'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Content_cleaned\n",
      "0     the app is great new features but crashes often\n",
      "1        love the app love the content but it crashes\n",
      "2          the app crashes too much it is frustrating\n",
      "3  the content is great it is easy to use it is great\n"
     ]
    }
   ],
   "source": [
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for applying TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Review</th>\n",
       "      <th>app</th>\n",
       "      <th>but</th>\n",
       "      <th>content</th>\n",
       "      <th>crashes</th>\n",
       "      <th>easy</th>\n",
       "      <th>features</th>\n",
       "      <th>frustrating</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>love</th>\n",
       "      <th>much</th>\n",
       "      <th>new</th>\n",
       "      <th>often</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the app is great new features but crashes often</td>\n",
       "      <td>0.266468</td>\n",
       "      <td>0.329142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329142</td>\n",
       "      <td>0.266468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417474</td>\n",
       "      <td>0.417474</td>\n",
       "      <td>0.217855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love the app love the content but it crashes</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>0.286843</td>\n",
       "      <td>0.286843</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>0.727649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the app crashes too much it is frustrating</td>\n",
       "      <td>0.288291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288291</td>\n",
       "      <td>0.288291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451664</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the content is great it is easy to use it is g...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461450</td>\n",
       "      <td>0.560375</td>\n",
       "      <td>0.373583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152714</td>\n",
       "      <td>0.292645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Original_Review       app       but  \\\n",
       "0    the app is great new features but crashes often  0.266468  0.329142   \n",
       "1       love the app love the content but it crashes  0.232224  0.286843   \n",
       "2         the app crashes too much it is frustrating  0.288291  0.000000   \n",
       "3  the content is great it is easy to use it is g...  0.000000  0.000000   \n",
       "\n",
       "    content   crashes      easy  features  frustrating     great        is  \\\n",
       "0  0.000000  0.266468  0.000000  0.417474     0.000000  0.329142  0.266468   \n",
       "1  0.286843  0.232224  0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.288291  0.000000  0.000000     0.451664  0.000000  0.288291   \n",
       "3  0.230725  0.000000  0.292645  0.000000     0.000000  0.461450  0.560375   \n",
       "\n",
       "         it      love      much       new     often       the        to  \\\n",
       "0  0.000000  0.000000  0.000000  0.417474  0.417474  0.217855  0.000000   \n",
       "1  0.232224  0.727649  0.000000  0.000000  0.000000  0.379717  0.000000   \n",
       "2  0.288291  0.000000  0.451664  0.000000  0.000000  0.235697  0.000000   \n",
       "3  0.373583  0.000000  0.000000  0.000000  0.000000  0.152714  0.292645   \n",
       "\n",
       "        too       use  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.451664  0.000000  \n",
       "3  0.000000  0.292645  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data to compute TF-IDF\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Content_cleaned'])\n",
    "\n",
    "# Create a DataFrame with the TF-IDF scores\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Insert the original reviews as the first column in the DataFrame\n",
    "tfidf_df.insert(0, 'Original_Review', df['Content_cleaned'])\n",
    "\n",
    "# Print the DataFrame with TF-IDF scores\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a **fun tip**: Take a look at the differences between this matrix and the one created using Bag of Words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try now applying what we have learned to the Netflix dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 39783\n",
      "Shape of the sparse matrix: (113292, 39783)\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('../DATASETS/preprocessed_text.csv')\n",
    "\n",
    "# Filling empty text that occurred after text preprocessing\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the model and transform the data\n",
    "tfidf = vectorizer.fit_transform(df['content_cleaned'])\n",
    "\n",
    "# Print the size of the vocabulary and the shape of the matrix\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"Shape of the sparse matrix: {tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the matrix will be the same as BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing a single row**\n",
    "\n",
    "Let's visualize a single review, just like we did in BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "i love to watch the movie s you have on here and the tv shows i love them growing_heart\n",
      "\n",
      "\n",
      "TF-IDF Matrix Representation as a Table:\n",
      "\n",
      "    Row Index           Word  TF-IDF Score\n",
      "0          44            and      0.109130\n",
      "1          44  growing_heart      0.562755\n",
      "2          44           have      0.157330\n",
      "3          44           here      0.332458\n",
      "4          44           love      0.417383\n",
      "5          44          movie      0.234126\n",
      "6          44             on      0.153703\n",
      "7          44          shows      0.188295\n",
      "8          44            the      0.207415\n",
      "9          44           them      0.285375\n",
      "10         44             to      0.110014\n",
      "11         44             tv      0.234482\n",
      "12         44          watch      0.172831\n",
      "13         44            you      0.163088\n"
     ]
    }
   ],
   "source": [
    "row_index = 44 # Specific row (review) we are inspecting\n",
    "\n",
    "# Display the original review text\n",
    "print(\"Original Text:\\n\")\n",
    "print(df['content_cleaned'][row_index])\n",
    "\n",
    "# Convert the sparse matrix row to a dense array for the selected document\n",
    "dense_array = tfidf[row_index].toarray()\n",
    "\n",
    "# Get the feature names (vocabulary) from the vectorizer\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Prepare data for the DataFrame\n",
    "data = {\n",
    "    'Row Index': [],\n",
    "    'Word': [],\n",
    "    'TF-IDF Score': []\n",
    "}\n",
    "\n",
    "# Populate the data with words and their corresponding non-zero TF-IDF scores\n",
    "for i in range(len(dense_array[0])):\n",
    "    score = dense_array[0][i]\n",
    "    if score > 0:  # Only include words with a non-zero TF-IDF score\n",
    "        data['Row Index'].append(row_index)\n",
    "        data['Word'].append(words[i])  # Get the actual word from the vocabulary\n",
    "        data['TF-IDF Score'].append(score)\n",
    "\n",
    "# Create a DataFrame to map the row index, word, and their corresponding TF-IDF score\n",
    "tfidf_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\n\\nTF-IDF Matrix Representation as a Table:\\n\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: All the single characters tokens are ignored by the default tokenizer (TfidfVectorizer). If you want single character tokens to be in the vocabulary, then you have to use a custom tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's cool to see that the 2 tokens with the highest TF-IDF score are: `growing_heart` and `love`. Which is enough to understand that it's a positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of TF-IDF\n",
    "\n",
    "### Pros\n",
    "\n",
    "- **Measuring relevance**: TF-IDF is great for figuring out which words are most relevant in a document. This can be really important for search engines and other text analysis apps.\n",
    "   \n",
    "- **Filtering Out Noise**: By reducing the impact of common words across documents, TF-IDF can filter out the usual \"noise\" or common words, allowing more relevant and unique content to stand out.\n",
    "   \n",
    "- **Simplicity and Efficiency**: TF-IDF is simple to understand and implement. It's also efficient, even with large datasets, because it requires minimal computational resources.\n",
    "\n",
    "### Cons\n",
    "\n",
    "- **Lack of Context Understanding**: TF-IDF doesn't take context into account, which can be a drawback for tasks that require understanding the meaning of the text.\n",
    "   \n",
    "- **Not Suitable for Short Texts**: In documents with very few words (like tweets or SMS messages), the TF-IDF scores might not be very informative since the frequency of words is generally low.\n",
    "   \n",
    "- **High-Dimensional Output**: The vectors generated by TF-IDF are usually high-dimensional (one dimension per unique word in the corpus). This can result in sparse matrices, which are more challenging to manage and process for some machine learning models.\n",
    "\n",
    "- **Out-Of-Vocabulary Issue**: Again,the algorithm does not work with new sequences that contain words not included in the vocabulary used for fitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

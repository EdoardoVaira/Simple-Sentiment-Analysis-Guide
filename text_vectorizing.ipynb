{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d117ad",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "## Import all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450f1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#¬†Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#¬†Text processing\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c59a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d42df88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>content_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc1cfcd2-dc8a-4ead-88d1-7f2b2dbb2662</td>\n",
       "      <td>Plsssss stoppppp giving screen limit like when...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>plsssss stoppppp give screen limit like ur wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7dfb1f90-f185-4e81-a97f-d38f0128e5a4</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3009acc4-8554-41cf-88de-cc5e2f6e45b2</td>\n",
       "      <td>üëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>thumb up thumb up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b3d27852-9a3b-4f74-9e16-15434d3ee324</td>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8be10073-2368-4677-b828-9ff5d06ea0b7</td>\n",
       "      <td>App is useful to certain phone brand ,,,,it is...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>app useful certain phone brand except phone tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId  \\\n",
       "0  cc1cfcd2-dc8a-4ead-88d1-7f2b2dbb2662   \n",
       "1  7dfb1f90-f185-4e81-a97f-d38f0128e5a4   \n",
       "2  3009acc4-8554-41cf-88de-cc5e2f6e45b2   \n",
       "3  b3d27852-9a3b-4f74-9e16-15434d3ee324   \n",
       "4  8be10073-2368-4677-b828-9ff5d06ea0b7   \n",
       "\n",
       "                                             content  score sentiment_label  \\\n",
       "0  Plsssss stoppppp giving screen limit like when...      2        negative   \n",
       "1                                               Good      5        positive   \n",
       "2                                                 üëçüëç      5        positive   \n",
       "3                                               Good      3         neutral   \n",
       "4  App is useful to certain phone brand ,,,,it is...      1        negative   \n",
       "\n",
       "                                     content_cleaned  \n",
       "0  plsssss stoppppp give screen limit like ur wat...  \n",
       "1                                               good  \n",
       "2                                  thumb up thumb up  \n",
       "3                                               good  \n",
       "4  app useful certain phone brand except phone tr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1463c41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewId            0\n",
       "content             0\n",
       "score               0\n",
       "sentiment_label     0\n",
       "content_cleaned    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc10d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328b593",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "This method creates literally a bag of words, without taking into account the semantic meaning of the words or their position in the sentence. First, all the inputs are tokenized. Then from all the unique tokens, the algorithm creates a vocabulary in alphabetical order. For every input sequence, the algorithm creates a matrix that has the length of the vocabulary and frequencies of each token are assigned to the corresponding index. The Bag of Words algorithm is implemented with the CountVectorizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa34b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34326\n",
      "(113292, 34326)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the model and transform the data\n",
    "bow = vectorizer.fit_transform(df['content_cleaned'])\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90edf48",
   "metadata": {},
   "source": [
    "We notice that the produced vocabulary is of size 34326, while our bag of words has 113292 vectors, each having the size of the vocabulary.\n",
    "\n",
    "Positive: \n",
    "- Sequences have a fixed size.\n",
    "\n",
    "Negative:\n",
    "- Order of words or semantic meaning is not preserved.\n",
    "- If we have a new sequence that contains new words that are not part of our vocabulary, it will not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e486e",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6075ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
